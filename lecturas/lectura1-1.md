# Opinions on Item-Based Collaborative Filtering Recommendation Algorithms (Sarwar et al, 2001)

Author: Valentina Rojas 

There are two major problems that recommender systems faced back in the day: scalability and the quality of recommendations. These of course are still problems we deal with today, but progress in hardware has given us a bit of a helping hand. In terms of these two challenges, another one is introduced: they are conflicting between one another, in terms of how improving one is undoubtedly making the other one worse. Even though it's true this must have been a concern back in the day, this, in my opinion, is in no way an accurate statement - there are so many ways to parallel and thread heavy load processes that this shouldn't be a limitation to shut down ambition in terms of developing an algorithm, but an aspect to be cautious with.

Item-based CF is the proposed paradigm to help with both of these challenges, giving a high quality recommendation based on the item space rather than the user space as its counterpart user-based CF does, the former being rather static in size compared to the latter, thus more efficient in performance. In this matter, a few other techniques are mentioned and I think some of them should've been taken into account, specifically bayesian networks as a method of clustering. Why? Because even though item-based CF does in fact work on a lower dimensionality space than user-based CF, it still relies on correlation to compute similarity between items, and in a very dense database this still gives an overhead that can be avoided to improve overall performance, and I think pre-clustering the user space considering other attributes would be a great way to do it, since it could be a task that can run on a smaller perodicity as it can be seen as an accessory technique to the main collaborative filtering algorithm - one that guides it in its computation.

In this same line, I think item-based CF doesn't tackle another big problem that wasn't mentioned: cold start. Either if you don't have enough users signed up or enough users who have purchased a target item, a cold start will most definitely lead to very unspecific and poor recommendations. Considering a parallel technique as it was mentioned before would, in my opinion, be very beneficial in this matter. Famous tech companies like Netflix or Spotify, even online magazines like Medium, give their users an initial short survey to profile them, this allows them to guide their recommendations in spite of how little information they have on them. For item-based CF, I think taking into account something like this in a pre-clustering algorithm would most definitely help in terms of performance and quality of recommendations since, as I mentioned before, it can be treated as a less periodic method since keeping your users clustered is something that can be achieved without it needing to be a recurrent task.

On a different note, another thing that caught my attention is how, given a similarity computation, a weighted sum method is presented as a prediction computation method. In my opinion this shouldn't be considered reliable for an accurate system, since one-time bought products that can be given a very high rating by a user, for example, could be given a higher priority with this method in contrast to other much more preferred products with an average or low rating.

In conclusion, item-based collaborative filtering seems to be a fairly good solution for the challenges faced by recommender systems, but it could have even better performance considering complimentary algorithms to guide it.
