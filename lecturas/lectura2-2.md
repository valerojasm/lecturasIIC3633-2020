# Comments on Bayesian Personalized Ranking from Implicit Feedback (Rendle et al, 2012)
Author: Valentina Rojas

One of the biggest advantages of using implicit feedback to develop a recommendation algorithm is that user input is not needed in the form of reviews or ratings, instead, their purchase history, clicks or views are used to compare what products are preferred over others. Rendle et al propose an optimization method tested in two famous algorithms that aims to model the user's behavior towards pairs of items instead of single items. By doing this, data is analyzed in the form of triplets $(u, i, j)$ that represent that a pair $(i,j)$ belongs to the total order $>_u$, which, according to the definition given, is true if and only if $i$ is preferred over $j$ by the user $u$.

I think one of the most fascinating benefits of this model, and well, actually the core of their research, is the way they tackle the problem of negatively classifying potentially attractive items to the user in traditional item-based CF with implicit feedback. From a bayesian point of view, products that haven't been purchased by a user will be trained as negative under the idea that the user doesn't prefer them. By creating the relation formerly described, we get to have distinctive positive and negative classes and a disjunct test dataset - the latter being those pairs we can't infer anything from: both $i$ and $j$ haven't been seen or purchased, or both of them have: these are the preferences we have to learn in terms of $>_u$.

Another very interesting decision I think they took is how they dealt with the fact that, for any interaction between a user $u$ and an item $i$, we could have an incredibly large amount of $(u,i,j)$ triplets, which could lead to extremely low performance. I wish they could've gone more in depth as to how SGD with bootstrap sampling really outperforms normal gradient descent in this matter - I'm sure it could be exponentially slower, but considering not all data is seen in every epoch, repeating the experiment could yield very different outcomes, since it heavily relies on chance and some dominant and important cases could be ruled out by this method. Nevertheless, this criterion outperforms the traditional implementation of both kNN and matrix factorization, so the case previously described is clearly not common, but I think it's definitely not impossible, especially in smaller datasets.
