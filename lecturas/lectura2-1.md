# Comments on Collaborative Filtering for Implicit Feedback Datasets (Hu et al, 2008)
Author: Valentina Rojas

With collaborative filtering, two types of user input are used to learn and therefore train our algorithms: explicit feedback and implicit feedback. The first one, collects explicit information given by users regarding their interest in an item, this can happen in the form of rating, reviews, etc. This type of input is said to be very popular amongst high quality recommender systems, but it has its flaws: sparsity, cold start, and many more. On the other hand we have implicit feedback. This type of input tracks information involuntarily (but with due consent) given by the user, such as clicks, views, browser history, etc. Hu et al developed an algorithm to use this type of feedback to create tv show recommendations, based on watching information of the users.

First thing I want to mention is that, training data is pre-processed in a way that, for every user and for every item, a $p_{ui}$ value is computed, which is 1 if the user has consumed item $i$ and 0 if they haven't. One of the biggest flaws here is that items that haven't been consumed by the user consciously, hence are not preferred by them, are put in the same bag as those items the user has no knowledge of - these are potential recommendations and start off as negatively classified items right away. On the other hand, there's a design decision in this same matter that, in my opinion, can also lower the quality of the recommendation, and this is that those shows that were consumed for less than 0.5 units (e.g. those that were watched by the user for less than half their duration) will also be given a $p_{ui}$ of 0 based on what I think are very weak grounds. Yes, a show that is quickly turned off is probably not in the user's biggest interests, but I think it would be important to check the timestamp of this action, since stopping a show versus catching a show in the middle or almost at the end of it is pretty different, considering they are using open television datasets.

In contrast to this, I think it was a great choice to give less importance to those shows that were watched subsequently to others for an extended period of time in the same channel - and I think this is why the decision I previously described stood out negatively for me, since it could've been taken into account just as well as this one. Bias adjustments are important to feed any model, but I think all these decisions should be taken carefully and follow some sort of tendency previously seen in users that is strong enough to consider it as harshly as they did with the less-than-half watching time situation. I read this short [article]([https://towardsdatascience.com/4-ways-to-supercharge-your-recommendation-system-aeac34678ce9](https://towardsdatascience.com/4-ways-to-supercharge-your-recommendation-system-aeac34678ce9)) recently that summarizes in its last bullet point what I try to say quite well: what drives your users, drives your success.

Last but not least, I think even though implicit feedback is easier to obtain than its explicit counterpart since it doesn't rely on user input, a great recommender system could be achieved by mixing both. In this paper, they mention how they implemented two other competing models, one using popularity as a baseline value. Since they used matrix factorization, I think it would be incredibly powerful to develop a model that, after decomposing in latent factores, consulted previous explicit information given by the user, whatever amount there is available, in a way to map the implicit feedback to the explicit feedback and then used this popularity baseline as an _a posteriori_ filtering. This would, in a very abstract way in this particular example, maybe help get some sense of one time situations. Let's say, watching an entire show would give it big priority in a user's recommendation, but maybe it was a one time thing because of a family gathering. Mapping it to what's known about the user ratings would make sense of this and give it the priority it actually deserves. It's a very coarse example, but in recommender systems beyond tv shows, one time situations are very common and this could maybe help guide them in the right path.
